{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ed52c95-07b9-4410-9897-39c1360e3fb5",
   "metadata": {},
   "source": [
    "# Genome Annotation\n",
    "\n",
    "Materials for the Genome Annotation a BRAKER & TSEBRA Genome Annotation workshop by Katharina Hoff (katharina.hoff@uni-greifswald.de).\n",
    "\n",
    "Please find slides for an introductory talk on genome annotation (with BRAKER and TSEBRA) at [genome_annotation_2023.pdf](genome_annotation.pdf) (**ToDo** @KatharinaHoff: add slides!)\n",
    "\n",
    "In the following, we will walk through the process of genome annotation on the example of a small proportion of the *Arabidopsis thaliana* genome.\n",
    "\n",
    "## Repeat masking\n",
    "\n",
    "Repetitive sequences are a huge problem for genome annotation. Some repeats only coincidentally look like protein-coding genes, others (such as transposases) are protein-coding genes, but we usually are not interested in any of these \"repeat genes\" when trying to find protein-coding genes in a novel genome. Thus, a genome should be repeat-masked prior gene prediction. \n",
    "\n",
    "Repeat masking is a resource and time-consuming step that is out of scope for this workshop. We recommend using RepeatModeler2 (paper at https://doi.org/10.1073/pnas.1921046117 , software at https://www.repeatmasker.org/RepeatModeler/ ) to construct a species-specific repeat library and mask the genome with RepeatMasker (ideally, you will perform these computations on a node with >70 threads, in a place with very fast storage i/o, possibly using RAM instead of actual hard drive as a temporary file storage place):\n",
    "\n",
    "```\n",
    "T=72 # you need a large number of threads and fast i/o storage\n",
    "GENOME=genome.fa\n",
    "DB=some_db_name_that_fits_to_species\n",
    "\n",
    "BuildDatabase -name ${DB} ${GENOME}\n",
    "RepeatModeler -database ${DB} -pa ${T} -LTRStruct\n",
    "RepeatMasker -pa 72 -lib ${DB}-families.fa -xsmall ${GENOME}\n",
    "```\n",
    "\n",
    "This results in a file `${GENOME}.masked`. \n",
    "\n",
    "<details>\n",
    "  <summary>Click to learn how to mask more rigorously when needed</summary>\n",
    "Depending on the kind of genome, plenty of unmasked repeats may still persist. This is generally an issue to be expected in large genomes, such as vertebrate genomes, and you will notice the problem if the count of predicted proteins is extremely high. You can try to overcome \"under-masking\" with the following steps (we are suggesting to use GNU parallel to speed up the process):\n",
    "\n",
    "```\n",
    "ln -s genome.masked.fa genome.fa\n",
    "splitMfasta.pl --minsize=25000000 ${GENOME}.masked\n",
    "\n",
    "# Running TRF\n",
    "ls genome.split.*.fa | parallel 'trf {} 2 7 7 80 10 50 500 -d -m -h'\n",
    "\n",
    "# Parsing TRF output\n",
    "# The script parseTrfOutput.py is from https://github.com/gatech-genemark/BRAKER2-exp\n",
    "ls genome.split.*.fa.2.7.7.80.10.50.500.dat | parallel 'parseTrfOutput.py {} --minCopies 1 --statistics {}.STATS > {}.raw.gff 2> {}.parsedLog'\n",
    "\n",
    "# Sorting parsed output...\"\n",
    "ls genome.split.*.fa.2.7.7.80.10.50.500.dat.raw.gff | parallel 'sort -k1,1 -k4,4n -k5,5n {} > {}.sorted 2> {}.sortLog'\n",
    "\n",
    "# Merging gff...\n",
    "FILES=genome.split.*.fa.2.7.7.80.10.50.500.dat.raw.gff.sorted\n",
    "for f in $FILES\n",
    "do\n",
    "    bedtools merge -i $f | awk 'BEGIN{OFS=\"\\t\"} {print $1,\"trf\",\"repeat\",$2+1,$3,\".\",\".\",\".\",\".\"}' > $f.merged.gff 2> $f.bedtools_merge.log\n",
    "done\n",
    "\n",
    "# Masking FASTA chunk\n",
    "ls genome.split.*.fa | parallel 'bedtools maskfasta -fi {} -bed {}.2.7.7.80.10.50.500.dat.raw.gff.sorted.merged.gff -fo {}.combined.masked -soft &> {}.bedools_mask.log'\n",
    "\n",
    "# Concatenate split genome\n",
    "cat genome.split.*.fa.combined.masked > genome.fa.combined.masked\n",
    "```\n",
    "\n",
    "The file `genome.fa.combined.masked` will be more rigorously masked.\n",
    "</details>\n",
    "\n",
    "## RNA-Seq alignment with HiSat2\n",
    "\n",
    "Spliced alignments of RNA-Seq short reads are a valuable information source for predicting protein-coding genes with high accuracy.\n",
    "\n",
    "![Figure 3 of Lomsadze et al. (2014)](et-rnaseq.png \"Figure 3 of Lomsadze et al. (2014) illustrates the use of RNA-Seq spliced alignments for predicting genes (with GeneMark-ET).\")\n",
    "Figure 3 of Lomsadze et al. (2014) illustrates the use of RNA-Seq spliced alignments for predicting genes (with GeneMark-ET), image source: https://doi.org/10.1093/nar/gku557.\n",
    "\n",
    "We will map the *Arabidopsis thaliana* Illumina RNA-Seq reads from library SRR934391 in files [~/alphafold_data/response/sra/SRR934391_1.fastq.gz](~/alphafold_data/response/sra/SRR934391_1.fastq.gz) and [~/alphafold_data/response/sra/SRR934391_2.fastq.gz](~/alphafold_data/response/sra/SRR934391_2.fastq.gz). These are paired-end data, i.e. one file contains the forward reads while the other contains in the same order the reverse reads. The length of reads is in this case 100 nt.\n",
    "\n",
    "We will use HiSat2 (publication at https://doi.org/10.1038/s41587-019-0201-4 , software at https://github.com/DaehwanKimLab/hisat2) to align these reads against a chunk of the *Arabidopsis thaliana* genome contained in the file [genome.fa](genome.fa). (You can in principle use any alignment tool capable of aligning RNA-seq reads to a genome, as long as it can perform spliced alignment.)\n",
    "\n",
    "First, we need to build an index from the genome file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d09c4a2-b87b-43ee-8685-53f3e927f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "# a toy data set to be used in this session is stored within the docker container\n",
    "# if not done so, yet, we copy that file into our current working directory\n",
    "if ! [ -f genome.fa ]\n",
    "then\n",
    "    ln -s /opt/BRAKER/example/genome.fa genome.fa\n",
    "fi\n",
    "\n",
    "# building the hisat2 index\n",
    "hisat2-build genome.fa genome-idx 1> hisat2-build.log 2> hisat2-build.err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf6d40-4dbe-4a25-88fb-d7d0e78da124",
   "metadata": {},
   "source": [
    "Inspect the log files [hisat2-build.log](hisat2-build.log) and [hisat2-build.err](hisat2-build.err) for possible errors.\n",
    "\n",
    "Next, we align the RNA-seq reads against the genome. Consider to **not** do this during the session. Performing this alignment took about 7 minutes with 70 threads. The precomputed output file is provided at `/home/genomics/workshop_material/genome_annotation/sra/SRR934391.sam`, and we will continue to use that pre-computed file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0d5c9-ae0e-47d5-aa06-c76ed2fd8bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=4 # adjust to number of threads that you booted with\n",
    "\n",
    "RNASEQDIR=/home/genomics/workshop_material/genome_annotation/sra/\n",
    "\n",
    "time hisat2 -p ${T} -q -x genome-idx -1 ${RNASEQDIR}/SRR934391_1.fastq.gz \\\n",
    "    -2 ${RNASEQDIR}/SRR934391_2.fastq.gz -S rnaseq.sam \\\n",
    "    1> hisat2-align.log 2> hisat2-align.err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63231a11-d314-4d14-ac77-be7751e1249f",
   "metadata": {},
   "source": [
    "Our goal is to extract information on spliced alignments/intron positons from the alignment output file. To achieve this, we will use a tool called bam2hints that is part of the Augustus software suite (software at https://github.com/Gaius-Augustus/Augustus ). However, this tool requires a sorted bam-file. Therefore, we first use Samtools (paper at https://doi.org/10.1093/bioinformatics/btp352 , software at https://github.com/samtools ) to convert the sam file to bam format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cdf9b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m24.449s\n",
      "user\t1m32.574s\n",
      "sys\t0m6.244s\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "T=4 # adjust to number of threads that you booted with, takes ~2 minutes with 4 threads\n",
    "\n",
    "SAMFILE=/home/genomics/workshop_material/genome_annotation/sra/SRR934391.sam\n",
    "\n",
    "time samtools view -@${T} -bSh ${SAMFILE} -o rnaseq.bam\n",
    "\n",
    "# if you computed your own rnaseq.sam file, delete it to save space on harddrive\n",
    "if [ -f rnaseq.sam ]\n",
    "then\n",
    "    rm rnaseq.sam\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67019eb-65c2-49ee-97cf-29259ee96fa9",
   "metadata": {},
   "source": [
    "Then, we sort that bam file (this will require a bit less than 4 GB of RAM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d462ce90-278c-49b5-b0ed-3f5d09aad94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bam_sort_core] merging from 12 files and 4 in-memory blocks...\n",
      "\n",
      "real\t0m53.787s\n",
      "user\t3m32.420s\n",
      "sys\t0m7.641s\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "T=4 # adjust to number of threads that you booted with, takes ~2 minutes with 4 threads\n",
    "\n",
    "time samtools sort -@${T} -n rnaseq.bam -o rnaseq.s.bam\n",
    "\n",
    "# remove the unsorted bam file to save space\n",
    "rm rnaseq.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a8a3d",
   "metadata": {},
   "source": [
    "## Annotation of protein coding genes\n",
    "\n",
    "Structural genome annotation is ideally performed by a combination of a statistical model (e.g. Hidden Markov Model derivate) and extrinsic evidence (e.g. from transcriptomics or known protein sequences). The statistical model parameters have to be adapted to the genomic properties of novel species. For adapting parameters, an initial set of high-quality training genes from the target species is required. This is tricky to obtain. BRAKER is a perl script that comprises several pipelines to automated the solution of this problem: fully automatically generate an initial set of training genes, train gene finders, and then predict genes with the trained parameters and extrinsic evidence.\n",
    "\n",
    "We will first take an approach to structural genome annotation that takes advantage both of RNA-Seq data, and a large database of known proteins, using BRAKER3 (poster from PAG2023 at https://www.researchgate.net/profile/Lars-Gabriel-3/publication/367409816_The_BRAKER3_Genome_Annotation_Pipeline/links/63d14cbae922c50e99c29c7a/The-BRAKER3-Genome-Annotation-Pipeline.pdf, all BRAKER software at https://github.com/Gaius-Augustus/BRAKER). If sufficient transcriptome data is available, then BRAKER3 is usually the best choice of pipeline. However, in the lack of transcriptome data, we need to consider alternative approaches. \n",
    "\n",
    "If transcriptome evidence is available but it just was not sufficient for obtaining good results with BRAKER3, then running BRAKER1 with RNA-Seq evidence (paper at https://doi.org/10.1093/bioinformatics/btv661) and protein supported gene prediction with BRAKER2 (paper at https://doi.org/10.1093/nargab/lqaa108), combined by TSEBRA (paper at https://doi.org/10.1186/s12859-021-04482-0, software at https://github.com/Gaius-Augustus/TSEBRA) is often a good option.\n",
    "\n",
    "In the total absence of transcriptome data, we recommend running either BRAKER2 with a large database of proteins, alone, or for larger genomes (such as vertebrates), we the recommend application of GALBA (preprint at https://www.biorxiv.org/content/10.1101/2023.04.10.536199v1.abstract, software at https://github.com/Gaius-Augustus/GALBA ) with reference proteomes of a few closely related, already annotated species.\n",
    "\n",
    "### BRAKER3\n",
    "\n",
    "BRAKER3 uses spliced aligned RNA-Seq data from Hisat2 (paper at https://www.nature.com/articles/s41587-019-0201-4, software at https://github.com/DaehwanKimLab/hisat2) for genome-guided transcriptome assembly with Stringtie (paper at https://www.nature.com/articles/nbt.3122, software at https://github.com/gpertea/stringtie). GeneMarkS-T (paper at https://academic.oup.com/nar/article/43/12/e78/2902598, software at http://exon.gatech.edu/genemark/license_download.cgi) is used to call protein coding genes in the transcripts. These transcripts are \"noisy\", therefore, a large database of proteins (e.g. an OrthoDB partition) is used to filter these predictions, using among other GeneMark-specific scripts including ProtHint (software at https://github.com/gatech-genemark/ProtHint) with Spaln (paper at https://academic.oup.com/bioinformatics/article/24/21/2438/191484, software at https://github.com/ogotoh/spaln) the fast search tool DIAMOND (paper at https://www.nature.com/articles/s41592-021-01101-x, software at https://github.com/bbuchfink/diamond). Both, the transcriptome and protein evidence is then used by GeneMark-ETP (preprint at https://www.biorxiv.org/content/10.1101/2023.01.13.524024v1, software at https://github.com/gatech-genemark/GeneMark-ETP) for self-training this HMM-based gene finder. This generates a training set for AUGUSTUS. Both, the GeneMark-ETP, and the AUGUSTUS gene set incorporate the evidence to some extent, and these gene sets are merged with TSEBRA (paper at https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-021-04482-0, software at https://github.com/Gaius-Augustus/TSEBRA) by BRAKER3.\n",
    "\n",
    "Training AUGUSTUS for a novel species usually comprises a step called etraining that adapts species-specific parameters of the statistical model of AUGUSTUS, and a step called optimize_augustus.pl that optimizes meta-parameters of that model. optimize_augustus.pl is very time-consuming, it yields usually ~2 percent points of accuracy on gene level. For this session, will disable this step with --skipOptimize. If you ever want to annotate a real new genome, make sure to delete --skipOptimize from your BRAKER calls (and expect substantially longer runtime). Also, GeneMark-ETP usually has a longer runtime. We will here set the maximal intergenic region for GeneMark-ETP to 10000. Please never apply this setting to a real genome annotation task, and expect a larger runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d27f3bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#**********************************************************************************\n",
      "#                               BRAKER CONFIGURATION                               \n",
      "#**********************************************************************************\n",
      "# BRAKER CALL: /opt/BRAKER/scripts/braker.pl --workingdir=BRAKER1 --genome=genome.fa --bam=rnaseq.s.bam --prot_seq=Viridiplantae.fa --AUGUSTUS_BIN_PATH=/usr/bin/ --AUGUSTUS_SCRIPTS_PATH=/usr/share/augustus/scripts/ --threads 4 --gm_max_intergenic 10000 --skipOptimize\n",
      "# Mon May  1 20:16:43 2023: braker.pl version 3.0.3\n",
      "# Mon May  1 20:16:43 2023:Both protein and RNA-Seq data in input detected. BRAKER will be executed in ETP mode (BRAKER3).\n",
      "#*********\n",
      "# Mon May  1 20:16:43 2023: Configuring of BRAKER for using external tools...\n",
      "# Mon May  1 20:16:43 2023: Trying to set $AUGUSTUS_CONFIG_PATH...\n",
      "# Mon May  1 20:16:43 2023: Found environment variable $AUGUSTUS_CONFIG_PATH.\n",
      "# Mon May  1 20:16:43 2023: Checking /usr/share/augustus/config/ as potential path for $AUGUSTUS_CONFIG_PATH.\n",
      "# Mon May  1 20:16:43 2023: Success! Setting $AUGUSTUS_CONFIG_PATH to /usr/share/augustus/config/!\n",
      "# Mon May  1 20:16:43 2023: WARNING: in file /opt/BRAKER/scripts/braker.pl at line 1894\n",
      "AUGUSTUS_CONFIG_PATH/species (in this case /usr/share/augustus/config//species) is not writeable. BRAKER will try to copy the AUGUSTUS config directory to a writeable location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Mon May  1 20:16:43 2023:Both protein and RNA-Seq data in input detected. BRAKER will be executed in ETP mode (BRAKER3).\n",
      "#*********\n",
      "# Mon May  1 20:16:44 2023: Log information is stored in file /home/katharina/git/GenomeAnnotation_Workshop2023/BRAKER1/braker.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#*********\n",
      "# WARNING: Detected whitespace in fasta header of file /home/katharina/git/GenomeAnnotation_Workshop2023/Viridiplantae.fa. This may later on cause problems! The pipeline will create a new file without spaces or \"|\" characters and a genome_header.map file to look up the old and new headers. This message will be suppressed from now on!\n",
      "#*********\n",
      "ERROR in file /opt/BRAKER/scripts/braker.pl at line 5473\n",
      "Failed to execute: /usr/bin/perl /opt/ETP/bin/gmetp.pl --cfg /home/katharina/git/GenomeAnnotation_Workshop2023/BRAKER1/GeneMark-ETP/etp_config.yaml --workdir /home/katharina/git/GenomeAnnotation_Workshop2023/BRAKER1/GeneMark-ETP --bam /home/katharina/git/GenomeAnnotation_Workshop2023/BRAKER1/GeneMark-ETP/etp_data/ --cores 4 --softmask  1>/home/katharina/git/GenomeAnnotation_Workshop2023/BRAKER1/errors/GeneMark-ETP.stdout 2>/home/katharina/git/GenomeAnnotation_Workshop2023/BRAKER1/errors/GeneMark-ETP.stderr\n",
      "Failed to execute: /usr/bin/perl /opt/ETP/bin/gmetp.pl --cfg /home/katharina/git/GenomeAnnotation_Workshop2023/BRAKER1/GeneMark-ETP/etp_config.yaml --workdir /home/katharina/git/GenomeAnnotation_Workshop2023/BRAKER1/GeneMark-ETP --bam /home/katharina/git/GenomeAnnotation_Workshop2023/BRAKER1/GeneMark-ETP/etp_data/ --cores 4 --softmask  1>/home/katharina/git/GenomeAnnotation_Workshop2023/BRAKER1/errors/GeneMark-ETP.stdout 2>/home/katharina/git/GenomeAnnotation_Workshop2023/BRAKER1/errors/GeneMark-ETP.stderr\n",
      "The most common problem is an expired or not present file ~/.gm_key or that GeneMark-ETP didn't receive enough evidence from the input data, in this case, see errors/GeneMark-ETP.stderr!\n",
      "\n",
      "real\t5m27.512s\n",
      "user\t13m37.758s\n",
      "sys\t0m14.621s\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\nT=4 # adjust to number of threads that you booted with, takes ~2 minutes with 4 threads\\n\\n# a toy data set to be used in this session is stored within the docker container\\n# if not done so, yet, we copy that file into our current working directory\\nif ! [ -f genome.fa ]\\nthen\\n    ln -s /opt/BRAKER/example/genome.fa genome.fa\\nfi\\n\\n\\ntime braker.pl --workingdir=BRAKER1 --genome=genome.fa --bam=rnaseq.s.bam \\\\\\n    --prot_seq=Viridiplantae.fa --AUGUSTUS_BIN_PATH=/usr/bin/ \\\\\\n    --AUGUSTUS_SCRIPTS_PATH=/usr/share/augustus/scripts/ \\\\\\n    --threads ${T} \\\\\\n    --gm_max_intergenic 10000 --skipOptimize # remember to remove this option if you are running a real job\\n #  remember to remove this option if you are running a real job\\n    # this call takes a few minutes even with --skipOptimize\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscript\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mT=4 # adjust to number of threads that you booted with, takes ~2 minutes with 4 threads\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# a toy data set to be used in this session is stored within the docker container\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# if not done so, yet, we copy that file into our current working directory\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mif ! [ -f genome.fa ]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mthen\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    ln -s /opt/BRAKER/example/genome.fa genome.fa\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfi\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mtime braker.pl --workingdir=BRAKER1 --genome=genome.fa --bam=rnaseq.s.bam \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --prot_seq=Viridiplantae.fa --AUGUSTUS_BIN_PATH=/usr/bin/ \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --AUGUSTUS_SCRIPTS_PATH=/usr/share/augustus/scripts/ \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --threads $\u001b[39;49m\u001b[38;5;132;43;01m{T}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --gm_max_intergenic 10000 --skipOptimize # remember to remove this option if you are running a real job\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m #  remember to remove this option if you are running a real job\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # this call takes a few minutes even with --skipOptimize\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2430\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2428\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2429\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2430\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2432\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2433\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\nT=4 # adjust to number of threads that you booted with, takes ~2 minutes with 4 threads\\n\\n# a toy data set to be used in this session is stored within the docker container\\n# if not done so, yet, we copy that file into our current working directory\\nif ! [ -f genome.fa ]\\nthen\\n    ln -s /opt/BRAKER/example/genome.fa genome.fa\\nfi\\n\\n\\ntime braker.pl --workingdir=BRAKER1 --genome=genome.fa --bam=rnaseq.s.bam \\\\\\n    --prot_seq=Viridiplantae.fa --AUGUSTUS_BIN_PATH=/usr/bin/ \\\\\\n    --AUGUSTUS_SCRIPTS_PATH=/usr/share/augustus/scripts/ \\\\\\n    --threads ${T} \\\\\\n    --gm_max_intergenic 10000 --skipOptimize # remember to remove this option if you are running a real job\\n #  remember to remove this option if you are running a real job\\n    # this call takes a few minutes even with --skipOptimize\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "T=4 # adjust to number of threads that you booted with, takes ~2 minutes with 4 threads\n",
    "\n",
    "# a toy data set to be used in this session is stored within the docker container\n",
    "# if not done so, yet, we copy that file into our current working directory\n",
    "if ! [ -f genome.fa ]\n",
    "then\n",
    "    ln -s /opt/BRAKER/example/genome.fa genome.fa\n",
    "fi\n",
    "\n",
    "\n",
    "time braker.pl --workingdir=BRAKER3 --genome=genome.fa --bam=/opt/BRAKER/example/rnaseq.bam \\\n",
    "    --prot_seq=Viridiplantae.fa --AUGUSTUS_BIN_PATH=/usr/bin/ \\\n",
    "    --AUGUSTUS_SCRIPTS_PATH=/usr/share/augustus/scripts/ --threads ${T} \\\n",
    "    --gm_max_intergenic 10000 --skipOptimize # remember to remove both these options for real jobs!\n",
    "    # this call takes a few minutes even with --skipOptimize and --gm_max_intergenic 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300410d-0522-4f4a-9400-88d63eab6e58",
   "metadata": {},
   "source": [
    "### BRAKER1\n",
    "\n",
    "BRAKER1 uses spliced alignment information from RNA-Seq for training GeneMark-ET, for selecting a training gene set for AUGUSTUS, and for predicting genes with AUGUSTUS. For this, the bam-file with RNA-Seq information needs to be converted to \"hints\". BRAKER can perform this step automatically, but it can take a long time. In particular if a lot of RNA-Seq libraries and a limited job runtim on a HPC system, you should perform this step prior running BRAKER for all the libraries in parallel. Therefore, we do it separately in this session. If you want to skip this step, the output file is provided at [rnaseq.hints](rnaseq.hints):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84751e1b-178a-470b-bada-c6409b14cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "bam2hints --intronsonly --in=rnaseq.s.bam --out=rnaseq.hints # takes 3-4 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc803820-947b-4e94-8f76-6e828b6e9fa3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c73700d-dacc-45a6-a4ba-582286f9c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "if [ -f rnaseq.s.bam ]; then\n",
    "    rm rnaseq.s.bam # also delete that bam file because you previously generated hints from it\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0adb72-a771-4ed5-9dfa-3ed23d70bbb0",
   "metadata": {},
   "source": [
    "Next, we will run BRAKER to predict genes in the genomic sequence with the prepared RNA-Seq intron evidence. Training AUGUSTUS for a novel species usually comprises a step called `etraining` that adapts species-specific parameters of the statistical model of AUGUSTUS, and a step called `optimize_augustus.pl` that optimizes meta-parameters of that model. `optimize_augustus.pl` is very time-consuming. For this session, will disable this step with `--skipOptimize`. If you ever want to annotate a real new genome, make sure to delete `--skipOptimize` from your BRAKER calls (and expect substantially longer runtime):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c34fe6-3fb7-443f-a026-2a8bf77d304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=4 # adjust to number of threads that you booted with, takes ~2.5 minutes on 6 threads\n",
    "\n",
    "export AUGUSTUS_CONFIG_PATH=\"${PWD}/config\" # tell BRAKER where to find writable AUGUSTUS parameters\n",
    "\n",
    "# delete output from a possible previous run if it exists\n",
    "if [ -d BRAKER1 ]\n",
    "then\n",
    "    rm -rf BRAKER1\n",
    "fi\n",
    "\n",
    "braker.pl --workingdir=BRAKER1 --genome=genome.fa --hints=rnaseq.hints --softmasking \\\n",
    "    --AUGUSTUS_BIN_PATH=/usr/bin/ --AUGUSTUS_SCRIPTS_PATH=/usr/share/augustus/scripts/ \\\n",
    "    --cores ${T} --gm_max_intergenic 10000 \\\n",
    "    --skipOptimize #  remember to remove this option if you are running a real job\n",
    "    # this call takes a few minutes even with --skipOptimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6a614-a5ca-445c-87d9-6c06614f1c34",
   "metadata": {},
   "source": [
    "Note that BRAKER by default expects scripts and binaries in a location relative to the `$AUGUSTUS_CONFIG_PATH`. We here changed the location of the `$AUGUSTUS_CONFIG_PATH` to a writable location. Therefore, we have to tell BRAKER where the scripts and binaries are (`--AUGUSTUS_BIN_PATH`, `--AUGUSTUS_CONFIG_PATH`).\n",
    "\n",
    "The most important output files that we will later use for running TSEBRA are \n",
    "\n",
    "   * [BRAKER1/augustus.hints.gtf](BRAKER1/augustus.hints.gtf)\n",
    "   * [BRAKER1/GeneMark-ET/genemark.gtf](BRAKER1/GeneMark-ET/genemark.gtf)\n",
    "   * [BRAKER1/hintsfile.gff](BRAKER1/hintsfile.gff)\n",
    "   \n",
    "The file [BRAKER1/what-to-cite.txt](BRAKER1/what-to-cite.txt) advises you on what papers should be cited if you were going to publish a manuscript on a gene set produced with BRAKER1.\n",
    "   \n",
    "### BRAKER2\n",
    "\n",
    "BRAKER2 uses spliced alignment information from a huge database of proteins against the target genome. Note: a set of proteins from one or a few related species is not sufficient for running BRAKER2 (in such a situation, consider using GALBA, instead, software at https://github.com/Gaius-Augustus/GALBA). A particular set of proteins of a closely related species can be appended to a larger database for running BRAKER2. However, BRAKER2 is not an ideal tool for recovering a complete set of proteins from a related species.\n",
    "\n",
    "The following call of BRAKER takes ~9 minutes on 6 threads, even when optimizing AUGUSTUS parameters is disabled. Consider **not** executing this during the live session, precomputed results are made available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a2f94-fd7f-4b2d-a69c-e977764ada9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=6 # adjust to number of threads that you booted with\n",
    "\n",
    "ORTHODB=${HOME}/alphafold_data/response/prothint_db/odb10_plants.fasta # adjust to suitable clade\n",
    "\n",
    "source ${HOME}/.bashrc # load GeneMark location\n",
    "\n",
    "export AUGUSTUS_CONFIG_PATH=${PWD}/config\n",
    "\n",
    "# delete output from a possible previous run if it exists\n",
    "if [ -d BRAKER2 ]\n",
    "then\n",
    "    rm -rf BRAKER2\n",
    "fi\n",
    "\n",
    "time braker.pl --workingdir=BRAKER2 --genome=genome.fa \\\n",
    "    --prot_seq=${ORTHODB} --softmasking \\\n",
    "    --AUGUSTUS_BIN_PATH=/usr/bin/ \\\n",
    "    --AUGUSTUS_SCRIPTS_PATH=/usr/share/augustus/scripts/ \\\n",
    "    --cores ${T} --gm_max_intergenic 10000 \\\n",
    "    --skipOptimize \\ # remember to remove this option if you are running a real job\n",
    "    2> braker_prothint.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee3d341-e69d-4ed5-a1ef-5af40a066f74",
   "metadata": {},
   "source": [
    "The most important output files that we will later use for running TSEBRA are \n",
    "\n",
    "   * [BRAKER2/augustus.hints.gtf](BRAKER2/augustus.hints.gtf)\n",
    "   * [BRAKER2/GeneMark-EP/genemark.gtf](BRAKER2/GeneMark-EP/genemark.gtf)\n",
    "   * [BRAKER2/hintsfile.gff](BRAKER2/hintsfile.gff)\n",
    "   \n",
    "The file [BRAKER2/what-to-cite.txt](BRAKER2/what-to-cite.txt) advises you on what papers should be cited if you were going to publish a manuscript on a gene set produced with BRAKER2.\n",
    "\n",
    "### TSEBRA\n",
    "\n",
    "TSEBRA is a tool for selecting a highly accurate gene set from several input sets according to supporting extrinsic evidence. We provide some background in [TSEBRA_Workshop.pdf](TSEBRA_Workshop.pdf). Here is how we run TSEBRA, today:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8600d47-a94f-4797-b30f-f1fcad3f0416",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "tsebra.py -g BRAKER1/augustus.hints.gtf,BRAKER1/GeneMark-ET/genemark.gtf,BRAKER2/augustus.hints.gtf,BRAKER2/GeneMark-EP/genemark.gtf \\\n",
    "    -e BRAKER1/hintsfile.gff,BRAKER2/hintsfile.gff -o tsebra.gtf 2> tsebra.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6513be99-73a5-4d19-9790-0b6ee16c45e9",
   "metadata": {},
   "source": [
    "Check the file [tsebra.log](tsebra.log) for possible errors. The final gene set is in file [tsebra.gtf](tsebra.gtf).\n",
    "\n",
    "## BUSCO assessment\n",
    "\n",
    "BUSCO (paper at https://doi.org/10.1002/cpz1.323, software at https://gitlab.com/ezlab/busco) can provide information on sensitivity with respect to a clade-specific core gene set. We will in the following extract the amino acid sequences of predicted genes, and obtain BUSCO scores for all gene sets that went into TSEBRA, and for the final gene set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8138e23-2e8e-4a2e-96a6-5c2c2a6ff827",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "# getAnnoFastaFromJoingenes.py does not have executability permission in Docker container\n",
    "# therefore make softlink for calling it with python explicitely\n",
    "if ! [ -f getAnnoFastaFromJoingenes.py ]\n",
    "then\n",
    "    ln -s /usr/share/augustus/scripts/getAnnoFastaFromJoingenes.py getAnnoFastaFromJoingenes.py\n",
    "fi\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f BRAKER1/augustus.hints.gtf -o b1-augustus\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f BRAKER1/GeneMark-ET/genemark.gtf -o genemark-et\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f BRAKER2/augustus.hints.gtf -o b2-augustus\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f BRAKER2/GeneMark-EP/genemark.gtf -o genemark-ep\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f tsebra.gtf -o tsebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce54627-f518-4c2a-8471-7b0be3d7f31c",
   "metadata": {},
   "source": [
    "This generated the following files with protein sequences:\n",
    "\n",
    "   * [b1-augustus.aa](b1-augustus.aa)\n",
    "   * [genemark-et.aa](genemark-et.aa)\n",
    "   * [b2-augustus.aa](b2-augustus.aa)\n",
    "   * [genemark-ep.aa](genemark-ep.aa)\n",
    "   * [tsebra.aa](tsebra.aa)\n",
    "   \n",
    "Let's have a quick look at the number of transcript products in each file ($\\neq$ number of genes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7c78b0a-354a-4af9-8a9f-6cc91b1a351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1-augustus.aa:278\n",
      "b2-augustus.aa:300\n",
      "genemark-ep.aa:279\n",
      "genemark-et.aa:266\n",
      "tsebra.aa:318\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "grep -c \">\" *.aa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abb2fe7-80ea-4fe2-9084-be860613edbf",
   "metadata": {},
   "source": [
    "First, we find the closest BUSCO lineage (we are working on *Arabidopsis thaliana*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50844f72-6582-48ab-a8af-d727a3e5ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "source conda_init\n",
    "conda activate busco_env\n",
    "\n",
    "busco --list-datasets > busco_lineages.txt 2> busco_lineages.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c8b743-b0a7-4cc8-aae6-a7ca98dfb593",
   "metadata": {},
   "source": [
    "All available lineages are now in [busco_lineages.txt](busco_lineages.txt). (Check [busco_lineages.log](busco_lineages.log) for possible errors.)\n",
    "\n",
    "Check at NCBI taxonomy (https://www.ncbi.nlm.nih.gov/taxonomy) the lineage of the target *Arabidopsis*. I believe the lineage is:\n",
    "\n",
    "`cellular organisms; Eukaryota; Viridiplantae; Streptophyta; Streptophytina; Embryophyta; Tracheophyta; Euphyllophyta; Spermatophyta; Magnoliopsida; Mesangiospermae; eudicotyledons; Gunneridae; Pentapetalae; rosids; malvids; Brassicales; Brassicaceae; Camelineae`\n",
    "\n",
    "Now find a related lineage in [busco_lineages.txt](busco_lineages.txt). `brassicales_odb10` is the closest lineage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006888e7-71ea-4560-b4c1-39c84697b56d",
   "metadata": {},
   "source": [
    "Next, we run a BUSCO assessment on all gene sets (this takes ~4 minutes with 6 threads):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17967a94-04d5-44e8-93b2-cec688e7488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing b1-augustus...\n",
      "Processing genemark-et...\n",
      "Processing b2-augustus...\n",
      "Processing genemark-ep...\n",
      "Processing tsebra...\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "source conda_init\n",
    "conda activate busco_env\n",
    "\n",
    "T=6 # adjust to number of threads that you booted with\n",
    "\n",
    "GENESETS=(b1-augustus genemark-et b2-augustus genemark-ep tsebra)\n",
    "\n",
    "for s in ${GENESETS[@]}; do\n",
    "    echo \"Processing ${s}...\"\n",
    "    if [ -d busco_${s} ]\n",
    "    then\n",
    "        rm -r busco_${s}\n",
    "    fi\n",
    "    busco -m proteins -i b1-augustus.aa -o busco_${s} \\\n",
    "        -l brassicales_odb10 -c ${T} &> busco_${s}.log\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0917f0eb-4b23-4434-a604-137dcbada7a4",
   "metadata": {},
   "source": [
    "Next, we visualize the BUSCO results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9308e93f-bd1c-477a-8252-584ae175e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "source conda_init\n",
    "conda activate busco_env\n",
    "\n",
    "if ! [ -d BUSCO_summaries ]\n",
    "then\n",
    "    mkdir BUSCO_summaries\n",
    "fi\n",
    "\n",
    "cp busco_*/short_summary*.txt BUSCO_summaries\n",
    "\n",
    "generate_plot.py -wd BUSCO_summaries &> generate_plot.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022a551a-5464-4450-9fee-f910798fd844",
   "metadata": {},
   "source": [
    "Check the file [generate_plot.log](generate_plot.log) for possible errors. This results in the following figure (stored at [BUSCO_summaries/busco_figure.png](BUSCO_summaries/busco_figure.png)):\n",
    "\n",
    "<img src=\"BUSCO_summaries/busco_figure.png\" alt=\"BUSCO results\" width=\"1000\"/>\n",
    "\n",
    "The data that we used in this session was selected purely on the criterion of feasible runtime. In a real scenario, with a complete genome, the BUSCO plot should look more like this (sensitivity should increase in the final TSEBRA set):\n",
    "\n",
    "<img src=\"busco_ideally.png\" alt=\"BUSCO results (ideally)\" width=\"1000\"/>\n",
    "\n",
    "## Data visualization in the UCSC Genome Browser\n",
    "\n",
    "Visualization of gene structures in context with extrinsic evidence is essential for coming to a decision on whether a gene set \"makes sense\" or \"does not make sense\". Typical problems that you may observe in a genome browser include \"split genes\" (where evidence implies two genes should in fact be a single gene) or \"joined genes\" (where evidence implies one gene should be split into two genes).\n",
    "\n",
    "The UCSC Genome Browser (publication at https://doi.org/10.1101/gr.229102) is one of the most popular genome browsers. It has the advantage that you do not have to install a browser instance on your own webserver. Instead, you only need to provide a certain data structure with your target data on a webserver. The UCSC Genome Browser servers can display your data from there. The data structures are called \"track data hubs\" or \"assembly hubs\" (paper at https://doi.org/10.1093/bioinformatics/btt637). \n",
    "\n",
    "MakeHub (paper at https://doi.org/10.1016/j.gpb.2019.05.003 , software at https://github.com/Gaius-Augustus/MakeHub ) is a python script that fully automates the generation of such track data hubs for novel genomes. In the following, we will generate a simple track data hub for the genome sequence that we annotated with BRAKER and TSEBRA (before starting this job, check whether you have around 10G of RAM available, top right corner of your web browser window):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e3029-7321-4efe-a66f-dfaef841b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=6 # adjust to number of threads that you booted with\n",
    "\n",
    "# merge hints\n",
    "cat BRAKER1/hintsfile.gff BRAKER2/hintsfile.gff > all_hints.gff\n",
    "\n",
    "make_hub.py -e katharina.hoff@uni-greifswald.de \\\n",
    "    --genome genome.fa --long_label \"A chunk from the Arabidopsis thaliana genome\" \\\n",
    "    --short_label at_chunk  --bam rnaseq.s.bam --cores ${T} \\\n",
    "    --display_bam_as_bam --latin_name \"Arabidopsis thaliana\" \\\n",
    "    --assembly_version \"artifically split custom assembly\" \\\n",
    "    --hints all_hints.gff --gene_track tsebra.gtf TSEBRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc653250-d5b7-4714-a346-e22563d67bc9",
   "metadata": {},
   "source": [
    "You can't perform the suggested `scp` command from the apphub, unless you have privileges on a University of Greifswald webserver. We have therefore copied a prepared hub in advance. The `hub.txt` is available at https://bioinf.uni-greifswald.de/hubs/at_chunk/hub.txt . Remember that link.\n",
    "\n",
    "In order to visualize your data, go to https://genome.ucsc.edu/ . Click on `My Data` -> `Track Hubs` -> choose the European mirror -> click on `Connected Hubs` and enter the link https://bioinf.uni-greifswald.de/hubs/at_chunk/hub.txt into the text window -> click on `Add Hub`. Congratulations, your Hub is now connected. You should be able to browse something like this: \n",
    "\n",
    "<img src=\"at_chunk.png\" alt=\"UCSC Genome Browser example\" width=\"1000\"/>\n",
    "\n",
    "### How to know which sequences to browse\n",
    "\n",
    "The long sequences are usually the most interesting to look at. The following command gives you the names of sequences in the order of descending length, you can copy-paste the sequence names into the search window in the UCSC Genome Browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72bd61f2-9007-45bd-83bf-5af23fee0995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1\t125040\n",
      "X2\t125100\n",
      "X3\t125100\n",
      "X4\t125100\n",
      "X5\t125100\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "N=5 # how many longest sequences would you like to know about\n",
    "\n",
    "summarizeACGTcontent.pl genome.fa | grep bases | head -${N} | sort -n \\\n",
    "   | perl -ne 'm/(\\d+)\\s+bases\\.\\s+(\\S+)/; print \"$2\\t$1\\n\";'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7681d88-0284-4819-bf10-955279525239",
   "metadata": {},
   "source": [
    "## How to run BRAKER (and other software) in Docker\n",
    "\n",
    "If you have a machine on which you have root permissions and Docker, you can run the exact same container as we have been using during this workshop as follows:\n",
    "\n",
    "```\n",
    "sudo docker run --rm -it -u root katharinahoff/response-notebook:devel bash\n",
    "```\n",
    "\n",
    "You can execute all shell commands that we covered in this notebook in that container. Note: you will have to re-copy the `$AUGUSTUS_CONFIG_PATH` and re-install GeneMark-ES/ET/EP. You might find the following tutorial helpful: https://www.tutorialspoint.com/how-to-copy-files-from-host-to-docker-container#:~:text=Another%20way%20to%20copy%20files,folder%20in%20the%20host%20machine.\n",
    "\n",
    "## How to run BRAKER (and other software) in Singularity\n",
    "\n",
    "If your HPC/server has Singularity, you I recommend to use a different docker image. It is a prerequisite that before executing that container, you download and install GeneMark-ES/ET/EP and the key file in your host home directory, and that you remember to which location that software was installed.\n",
    "\n",
    "The \"BRAKER\" container is not containing exactly the same version of BRAKER as the Docker container. Instead, it contains the BRAKER1 and BRAKER2 versions that will be included in BRAKER3. Results of the two containers might therefore differ slightly. The BRAKER container has been adapted to the needs of HPC SLURM Singularity users.\n",
    "\n",
    "```\n",
    "if ! command -v singularity; then\n",
    "    module load singularity\n",
    "fi\n",
    "\n",
    "if ! command -v singularity; then\n",
    "    echo \"Please install singularity!\"\n",
    "fi\n",
    "\n",
    "singularity build braker.sif docker://katharinahoff/braker-notebook:devel\n",
    "```\n",
    "\n",
    "Here is an example call for BRAKER1:\n",
    "\n",
    "```\n",
    "singularity exec -B $PWD:$PWD braker.sif braker.pl --genome=genome.fa --hints=rnaseq_hints.gff --softmasking --threads=24 --gm_max_intergenic 10000 --GENEMARK_PATH=${HOME}/bin/gm_et_linux_64/gmes_petap --workingdir=braker1\n",
    "```\n",
    "You have to adapt the location of gmes_petap to your system, and you have to adapt input and output names.\n",
    "\n",
    "Here is an example call for BRAKER2:\n",
    "\n",
    "```\n",
    "singularity exec -B $PWD:$PWD braker.sif braker.pl --genome=genome.fa --prot_seq=orthodb.fa --softmasking --threads=24 --gm_max_intergenic 10000 --GENEMARK_PATH=${HOME}/bin/gm_et_linux_64/gmes_petap --workingdir=braker2 \n",
    "```\n",
    "\n",
    "This new version of BRAKER does not produce output files augustus.hints.gtf, anymore. Instead, it writes output files called braker.gtf (which contains the combined gene set of AUGUSTUS and GeneMark-ES/ET/EP). Subsequently, the TSEBRA call is much simpler:\n",
    "\n",
    "```\n",
    "singularity exec -B $PWD:$PWD braker.sif tsebra.py -g braker1/braker.gtf,braker2/braker.gtf \\\n",
    "    -e braker1/hintsfile.gff,braker2/hintsfile.gff -o tsebra.gtf\n",
    "```\n",
    "\n",
    "The BRAKER container does not contain BUSCO, but it contains Hisat2, Samtools, and MakeHub. They can be used in a similar way as described for BRAKER1, BRAKER2, and TSEBRA.\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### I have 80.000 genes predicted by BRAKER/TSEBRA in a full genome, what shall I do?\n",
    "\n",
    "Please first check whether you are referring to genes, or to transcripts. BRAKER predicts alternative isoforms. If RNA-Seq data supports this, the number of alternative transcripts may be large, but likely true. If it's really genes that you counted, then 80.000 sounds way too much, indeed. Most likely, GeneMark-ET/ES/EP produced highly fragmented training genes for AUGUSTUS. This will also lead to highly fragmented genes predicted by AUGUSTUS. First, check whether you genome has been masked for repeats. Consider using the additional TRF masking desribed at the top of this notebook. If that does not help, and if you have a protein set of closely related species at hand, consider using that protein set as sole training data for AUGUSTUS. You can use GALBA for this (https://github.com/Gaius-Augustus/GALBA). Also, keep an eye out for the appearance of BRAKER3 because that may also fix your problem.\n",
    "\n",
    "### I have only 10.000 genes predicted by BRAKER/TSEBRA in a full genome, what shall I do?\n",
    "\n",
    "Check whether the BRAKER output files produced more genes than TSEBRA. By default, TSEBRA will discard genes without evidence. If you have only little evidence for your species, TSEBRA might be a bad idea.\n",
    "\n",
    "### How do I know how many genes to expect?\n",
    "\n",
    "Hard to say. You can download gene sets of related species e.g. from NCBI Genomes, and count. Some gene sets tend to be \"underannotated\", i.e. they may represent rather the lower numbers of what might be realistic. Katharina usually gets nervous about more than 40000 genes and fewer than 20000 genes. These are definitely weird gene counts. Otherwise: always inspect your gene set in a Genome Browser such as the UCSC Genome Browser to identify problems.\n",
    "\n",
    "### I have long isoseq RNA-Seq transcripts, can I put them into BRAKER?\n",
    "\n",
    "No. But we have other instructions for you at https://github.com/Gaius-Augustus/BRAKER/blob/master/docs/long_reads/long_read_protocol.md . Please note: isoseq data does not always aid structural genome annotation over short read RNA-Seq data.\n",
    "\n",
    "### The BUSCO scores of my genome are higher than those of my protein, why?\n",
    "\n",
    "Some short housekeeping genes are commonly masked during repeat masking. They won't show up in a BRAKER gene set. You can manually add them from BUSCO output to a final gene set. We currently do not provide an automated workflow for this.\n",
    "\n",
    "### I opened an issue on GitHub about BRAKER or TSEBRA 100 days ago, nobody replied, why?\n",
    "\n",
    "We are a small team of developers. We try our best and usually respond to well described and easy-to-solve issues within a rather short time frame. Solving other issues may take considerable amounts of time that we simply do not have, or they may be described in a way that we don't know what do with them... please be patient with us.\n",
    "\n",
    "### I have a problem, whom do I tell?\n",
    "\n",
    "Please read through the Issues on Github. If the issue does not exist, yet, open an issue.\n",
    "\n",
    "### The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60ef6b-a759-4501-bbab-bf3732c18324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
